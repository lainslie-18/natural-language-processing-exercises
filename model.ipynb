{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "db42748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25c96b",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Take the work we did in the lessons further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "686f4e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>https://codeup.com/codeup-news/vet-tec-funding...</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>happy announce vet tec benefits available used...</td>\n",
       "      <td>happi announc vet tec benefit avail use campu ...</td>\n",
       "      <td>happy announce vet tec benefit available used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas Campus Re-opens With New Grant Partner</td>\n",
       "      <td>https://codeup.com/codeup-news/dallas-campus-r...</td>\n",
       "      <td>We are happy to announce that our Dallas campu...</td>\n",
       "      <td>happy announce dallas campus reopened better y...</td>\n",
       "      <td>happi announc dalla campu reopen better yet ne...</td>\n",
       "      <td>happy announce dallas campus reopened better y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Codeup the Best Bootcamp in San Antonio…or ...</td>\n",
       "      <td>https://codeup.com/codeup-news/is-codeup-the-b...</td>\n",
       "      <td>Looking for the best data science bootcamp in ...</td>\n",
       "      <td>looking best data science bootcamp world best ...</td>\n",
       "      <td>look best data scienc bootcamp world best code...</td>\n",
       "      <td>looking best data science bootcamp world best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Launches First Podcast: Hire Tech</td>\n",
       "      <td>https://codeup.com/codeup-news/codeup-launches...</td>\n",
       "      <td>Any podcast enthusiasts out there? We are plea...</td>\n",
       "      <td>podcast enthusiasts pleased announce release c...</td>\n",
       "      <td>podcast enthusiast pleas announc releas codeup...</td>\n",
       "      <td>podcast enthusiast pleased announce release co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>https://codeup.com/codeup-news/codeup-start-da...</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>approach end january wanted look forward next ...</td>\n",
       "      <td>approach end januari want look forward next st...</td>\n",
       "      <td>approach end january wanted look forward next ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  VET TEC Funding Now Available For Dallas Veterans   \n",
       "1      Dallas Campus Re-opens With New Grant Partner   \n",
       "2  Is Codeup the Best Bootcamp in San Antonio…or ...   \n",
       "3           Codeup Launches First Podcast: Hire Tech   \n",
       "4                  Codeup Start Dates for March 2022   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://codeup.com/codeup-news/vet-tec-funding...   \n",
       "1  https://codeup.com/codeup-news/dallas-campus-r...   \n",
       "2  https://codeup.com/codeup-news/is-codeup-the-b...   \n",
       "3  https://codeup.com/codeup-news/codeup-launches...   \n",
       "4  https://codeup.com/codeup-news/codeup-start-da...   \n",
       "\n",
       "                                            original  \\\n",
       "0  We are so happy to announce that VET TEC benef...   \n",
       "1  We are happy to announce that our Dallas campu...   \n",
       "2  Looking for the best data science bootcamp in ...   \n",
       "3  Any podcast enthusiasts out there? We are plea...   \n",
       "4  As we approach the end of January we wanted to...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  happy announce vet tec benefits available used...   \n",
       "1  happy announce dallas campus reopened better y...   \n",
       "2  looking best data science bootcamp world best ...   \n",
       "3  podcast enthusiasts pleased announce release c...   \n",
       "4  approach end january wanted look forward next ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  happi announc vet tec benefit avail use campu ...   \n",
       "1  happi announc dalla campu reopen better yet ne...   \n",
       "2  look best data scienc bootcamp world best code...   \n",
       "3  podcast enthusiast pleas announc releas codeup...   \n",
       "4  approach end januari want look forward next st...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  happy announce vet tec benefit available used ...  \n",
       "1  happy announce dallas campus reopened better y...  \n",
       "2  looking best data science bootcamp world best ...  \n",
       "3  podcast enthusiast pleased announce release co...  \n",
       "4  approach end january wanted look forward next ...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use function to pull in prepped codeup blog data\n",
    "codeup_df = prepare.prep_clean_codeup_data()\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "27aa5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             happy\n",
       "1          announce\n",
       "2               vet\n",
       "3               tec\n",
       "4           benefit\n",
       "           ...     \n",
       "5016          first\n",
       "5017          apply\n",
       "5018          apply\n",
       "5019          pride\n",
       "5020    scholarship\n",
       "Length: 5021, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all words in lemmatized column\n",
    "words = pd.Series(' '.join(codeup_df.lemmatized).split())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f13e630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>65</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup</th>\n",
       "      <td>63</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>62</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>56</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>42</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hundred</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prework</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skillful</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nba</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            raw_count  frequency  augmented_frequency\n",
       "tech               65   0.012946             1.000000\n",
       "codeup             63   0.012547             0.969231\n",
       "program            62   0.012348             0.953846\n",
       "career             56   0.011153             0.861538\n",
       "system             42   0.008365             0.646154\n",
       "...               ...        ...                  ...\n",
       "hundred             1   0.000199             0.015385\n",
       "generation          1   0.000199             0.015385\n",
       "prework             1   0.000199             0.015385\n",
       "skillful            1   0.000199             0.015385\n",
       "nba                 1   0.000199             0.015385\n",
       "\n",
       "[1526 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate term frequency for blog data\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c988334f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22x1517 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3261 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vectorizer object & apply\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(codeup_df.lemmatized)\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5df426ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>11222</th>\n",
       "      <th>12</th>\n",
       "      <th>1218</th>\n",
       "      <th>13</th>\n",
       "      <th>13week</th>\n",
       "      <th>13weeks</th>\n",
       "      <th>...</th>\n",
       "      <th>wwwworkintexascom</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027445</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100994</td>\n",
       "      <td>0.086617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085566</td>\n",
       "      <td>0.038472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    01        10  100  101     11222        12  1218        13  13week  \\\n",
       "0  0.0  0.000000  0.0  0.0  0.038066  0.000000   0.0  0.000000     0.0   \n",
       "1  0.0  0.000000  0.0  0.0  0.000000  0.000000   0.0  0.000000     0.0   \n",
       "2  0.0  0.049849  0.0  0.0  0.000000  0.000000   0.0  0.000000     0.0   \n",
       "3  0.0  0.000000  0.0  0.0  0.000000  0.000000   0.0  0.000000     0.0   \n",
       "4  0.0  0.000000  0.0  0.0  0.000000  0.080909   0.0  0.080909     0.0   \n",
       "\n",
       "   13weeks  ...  wwwworkintexascom      year  yes       yet      youd  \\\n",
       "0      0.0  ...           0.000000  0.016323  0.0  0.000000  0.000000   \n",
       "1      0.0  ...           0.100994  0.086617  0.0  0.084006  0.000000   \n",
       "2      0.0  ...           0.000000  0.021376  0.0  0.000000  0.045127   \n",
       "3      0.0  ...           0.000000  0.077844  0.0  0.000000  0.000000   \n",
       "4      0.0  ...           0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "\n",
       "      youll     youre     youve  zero  zoom  \n",
       "0  0.027445  0.043560  0.000000   0.0   0.0  \n",
       "1  0.000000  0.000000  0.000000   0.0   0.0  \n",
       "2  0.000000  0.085566  0.038472   0.0   0.0  \n",
       "3  0.000000  0.000000  0.000000   0.0   0.0  \n",
       "4  0.000000  0.000000  0.110174   0.0   0.0  \n",
       "\n",
       "[5 rows x 1517 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out feature extraction results\n",
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb7c4b",
   "metadata": {},
   "source": [
    "## Moving to news article data so we can try to predict category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58170a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBI cancels licence of Maha-based Independence...</td>\n",
       "      <td>RBI has cancelled licence of Maharashtra-based...</td>\n",
       "      <td>business</td>\n",
       "      <td>rbi cancelled licence maharashtrabased indepen...</td>\n",
       "      <td>rbi cancel licenc maharashtrabas independ coop...</td>\n",
       "      <td>rbi cancelled licence maharashtrabased indepen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boost to EVs a big step: Windmill Capital</td>\n",
       "      <td>Increased use of EVs in public transport, spec...</td>\n",
       "      <td>business</td>\n",
       "      <td>increased use evs public transport special mob...</td>\n",
       "      <td>increas use ev public transport special mobil ...</td>\n",
       "      <td>increased use ev public transport special mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook parent Meta's $230-billion wipeout bi...</td>\n",
       "      <td>Facebook's parent Meta's shares plunged 27% an...</td>\n",
       "      <td>business</td>\n",
       "      <td>facebook ' s parent meta ' s shares plunged 27...</td>\n",
       "      <td>facebook ' s parent meta ' s share plung 27 th...</td>\n",
       "      <td>facebook ' s parent meta ' s share plunged 27 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesla co-worker used N-word, threw a hot tool ...</td>\n",
       "      <td>A former Tesla worker has filed a lawsuit agai...</td>\n",
       "      <td>business</td>\n",
       "      <td>former tesla worker filed lawsuit company fail...</td>\n",
       "      <td>former tesla worker file lawsuit compani fail ...</td>\n",
       "      <td>former tesla worker filed lawsuit company fail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mark Zuckerberg loses $31 bn in one of the big...</td>\n",
       "      <td>Meta CEO Mark Zuckerberg's wealth dropped by $...</td>\n",
       "      <td>business</td>\n",
       "      <td>meta ceo mark zuckerberg ' s wealth dropped 31...</td>\n",
       "      <td>meta ceo mark zuckerberg ' s wealth drop 31 bi...</td>\n",
       "      <td>meta ceo mark zuckerberg ' s wealth dropped 31...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  RBI cancels licence of Maha-based Independence...   \n",
       "1          Boost to EVs a big step: Windmill Capital   \n",
       "2  Facebook parent Meta's $230-billion wipeout bi...   \n",
       "3  Tesla co-worker used N-word, threw a hot tool ...   \n",
       "4  Mark Zuckerberg loses $31 bn in one of the big...   \n",
       "\n",
       "                                            original  category  \\\n",
       "0  RBI has cancelled licence of Maharashtra-based...  business   \n",
       "1  Increased use of EVs in public transport, spec...  business   \n",
       "2  Facebook's parent Meta's shares plunged 27% an...  business   \n",
       "3  A former Tesla worker has filed a lawsuit agai...  business   \n",
       "4  Meta CEO Mark Zuckerberg's wealth dropped by $...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  rbi cancelled licence maharashtrabased indepen...   \n",
       "1  increased use evs public transport special mob...   \n",
       "2  facebook ' s parent meta ' s shares plunged 27...   \n",
       "3  former tesla worker filed lawsuit company fail...   \n",
       "4  meta ceo mark zuckerberg ' s wealth dropped 31...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  rbi cancel licenc maharashtrabas independ coop...   \n",
       "1  increas use ev public transport special mobil ...   \n",
       "2  facebook ' s parent meta ' s share plung 27 th...   \n",
       "3  former tesla worker file lawsuit compani fail ...   \n",
       "4  meta ceo mark zuckerberg ' s wealth drop 31 bi...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  rbi cancelled licence maharashtrabased indepen...  \n",
       "1  increased use ev public transport special mobi...  \n",
       "2  facebook ' s parent meta ' s share plunged 27 ...  \n",
       "3  former tesla worker filed lawsuit company fail...  \n",
       "4  meta ceo mark zuckerberg ' s wealth dropped 31...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use function to pull in prepped news data\n",
    "news_df = prepare.prep_clean_news_data()\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8cfb90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all lemmatized words by category\n",
    "entertainment_words = pd.Series(' '.join(news_df.lemmatized[news_df.category == 'entertainment'].astype(str)).split())\n",
    "business_words = pd.Series(' '.join(news_df.lemmatized[news_df.category == 'business'].astype(str)).split())\n",
    "technology_words = pd.Series(' '.join(news_df.lemmatized[news_df.category == 'technology'].astype(str)).split())\n",
    "sports_words = pd.Series(' '.join(news_df.lemmatized[news_df.category == 'sports'].astype(str)).split())\n",
    "all_words = pd.Series(' '.join(news_df.lemmatized).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d8a1e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate term frequency by category for news data\n",
    "entertainment_tf = (pd.DataFrame({'raw_count': entertainment_words.value_counts()})\n",
    "                 .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    "                 .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))\n",
    "business_tf = (pd.DataFrame({'raw_count': business_words.value_counts()})\n",
    "                 .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    "                 .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))\n",
    "technology_tf = (pd.DataFrame({'raw_count': technology_words.value_counts()})\n",
    "                 .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    "                 .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))\n",
    "sports_tf = (pd.DataFrame({'raw_count': sports_words.value_counts()})\n",
    "                 .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    "                 .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "256a28e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>57</td>\n",
       "      <td>0.061822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>16</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>0.280702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added</th>\n",
       "      <td>14</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.245614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>13</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.228070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>12</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>11</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.192982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actress</th>\n",
       "      <td>11</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.192982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrote</th>\n",
       "      <td>7</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>0.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asked</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.087719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           raw_count  frequency  augmented_frequency\n",
       "'                 57   0.061822             1.000000\n",
       "said              16   0.017354             0.280702\n",
       "added             14   0.015184             0.245614\n",
       "actor             13   0.014100             0.228070\n",
       "s                 12   0.013015             0.210526\n",
       "film              11   0.011931             0.192982\n",
       "actress           11   0.011931             0.192982\n",
       "wrote              7   0.007592             0.122807\n",
       "asked              6   0.006508             0.105263\n",
       "instagram          5   0.005423             0.087719"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top entertainment term frequencies\n",
    "entertainment_tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8d43bd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>42</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>31</td>\n",
       "      <td>0.030126</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>21</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>13</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billion</th>\n",
       "      <td>11</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>8</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fell</th>\n",
       "      <td>7</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added</th>\n",
       "      <td>7</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>india</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          raw_count  frequency  augmented_frequency\n",
       "'                42   0.040816             1.000000\n",
       "s                31   0.030126             0.738095\n",
       "said             21   0.020408             0.500000\n",
       "company          13   0.012634             0.309524\n",
       "billion          11   0.010690             0.261905\n",
       "facebook          8   0.007775             0.190476\n",
       "fell              7   0.006803             0.166667\n",
       "added             7   0.006803             0.166667\n",
       "value             6   0.005831             0.142857\n",
       "india             6   0.005831             0.142857"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top business term frequencies\n",
    "business_tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0799b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>43</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>34</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billion</th>\n",
       "      <td>20</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>15</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>11</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta</th>\n",
       "      <td>10</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fell</th>\n",
       "      <td>9</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>8</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>8</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>7</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.162791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          raw_count  frequency  augmented_frequency\n",
       "'                43   0.041992             1.000000\n",
       "s                34   0.033203             0.790698\n",
       "billion          20   0.019531             0.465116\n",
       "said             15   0.014648             0.348837\n",
       "facebook         11   0.010742             0.255814\n",
       "meta             10   0.009766             0.232558\n",
       "fell              9   0.008789             0.209302\n",
       "revenue           8   0.007812             0.186047\n",
       "u                 8   0.007812             0.186047\n",
       "user              7   0.006836             0.162791"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top technology term frequencies\n",
    "technology_tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0076689b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>21</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>18</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added</th>\n",
       "      <td>14</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>11</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>11</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>india</th>\n",
       "      <td>8</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>8</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coach</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          raw_count  frequency  augmented_frequency\n",
       "'                21   0.022082             1.000000\n",
       "said             18   0.018927             0.857143\n",
       "added            14   0.014721             0.666667\n",
       "team             11   0.011567             0.523810\n",
       "s                11   0.011567             0.523810\n",
       "india             8   0.008412             0.380952\n",
       "world             8   0.008412             0.380952\n",
       "coach             6   0.006309             0.285714\n",
       "positive          6   0.006309             0.285714\n",
       "match             6   0.006309             0.285714"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top sports term frequencies\n",
    "sports_tf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0b6ca",
   "metadata": {},
   "source": [
    "It appears that business and technology top words used are pretty aligned so it may be difficult to differentiate between these categories using only top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1471ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for help getting the next two code blocks to work\n",
    "\n",
    "# def idf(word, cat):\n",
    "#     n_occurences = news_df[news_df.category == cat].lemmatized.str.contains(word).sum()\n",
    "#     return len(news_df[news_df.category ==  cat]) / n_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "76e06cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for help with this\n",
    "\n",
    "# unique_words = entertainment_words.unique()\n",
    "\n",
    "# a = pd.DataFrame(dict(word=unique_words))\n",
    "# a = a.assign(idf = lambda x: idf(x.word, 'entertainment'))\n",
    "# # a = a.assign(idf = lambda df: df.word.apply(idf, args))\n",
    "# # sort the data for presentation purposes\n",
    "# # a = a.set_index('word')\n",
    "# a   \n",
    "    \n",
    "# #  .sort_values(by='idf', ascending=False)\n",
    "# #  .head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7f58a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25x562 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 733 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vectorizer object & apply to entertainment category\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(news_df.lemmatized[news_df.category ==  'entertainment'])\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fe382ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>2007</th>\n",
       "      <th>2020</th>\n",
       "      <th>2022</th>\n",
       "      <th>20yearold</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wrapup</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>youi</th>\n",
       "      <th>zapkeycom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        100  10th   11   15       19  2007  2020     2022  20yearold  \\\n",
       "0  0.000000   0.0  0.0  0.0  0.00000   0.0   0.0  0.00000        0.0   \n",
       "1  0.000000   0.0  0.0  0.0  0.00000   0.0   0.0  0.00000        0.0   \n",
       "2  0.000000   0.0  0.0  0.0  0.14501   0.0   0.0  0.14501        0.0   \n",
       "3  0.000000   0.0  0.0  0.0  0.00000   0.0   0.0  0.00000        0.0   \n",
       "4  0.145624   0.0  0.0  0.0  0.00000   0.0   0.0  0.00000        0.0   \n",
       "\n",
       "         21  ...     would  wrapup   written  wrong     wrote  year  yet   yo  \\\n",
       "0  0.000000  ...  0.000000     0.0  0.000000    0.0  0.220266   0.0  0.0  0.0   \n",
       "1  0.000000  ...  0.123156     0.0  0.152882    0.0  0.099157   0.0  0.0  0.0   \n",
       "2  0.128517  ...  0.000000     0.0  0.000000    0.0  0.000000   0.0  0.0  0.0   \n",
       "3  0.000000  ...  0.000000     0.0  0.000000    0.0  0.000000   0.0  0.0  0.0   \n",
       "4  0.000000  ...  0.000000     0.0  0.000000    0.0  0.000000   0.0  0.0  0.0   \n",
       "\n",
       "   youi  zapkeycom  \n",
       "0   0.0    0.00000  \n",
       "1   0.0    0.00000  \n",
       "2   0.0    0.14501  \n",
       "3   0.0    0.00000  \n",
       "4   0.0    0.00000  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out feature extraction results from entertainment category\n",
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e29dfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform tfidf object on news_df articles\n",
    "X = tfidf.fit_transform(news_df.lemmatized)\n",
    "y = news_df.category\n",
    "\n",
    "# split the data into X train and test, and y train and test, stratifying on category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f6b8010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression model\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "train['lm_predicted'] = lm.predict(X_train)\n",
    "test['lm_predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "465475c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.25%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "lm_predicted                                              \n",
      "business             15              0       0           2\n",
      "entertainment         0             20       0           0\n",
      "sports                0              0      20           0\n",
      "technology            5              0       0          18\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.75      0.81        20\n",
      "entertainment       1.00      1.00      1.00        20\n",
      "       sports       1.00      1.00      1.00        20\n",
      "   technology       0.78      0.90      0.84        20\n",
      "\n",
      "     accuracy                           0.91        80\n",
      "    macro avg       0.92      0.91      0.91        80\n",
      " weighted avg       0.92      0.91      0.91        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for train dataset\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.lm_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ae698e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "lm_predicted                                              \n",
      "business              2              0       0           4\n",
      "entertainment         2              4       0           0\n",
      "sports                0              1       5           0\n",
      "technology            1              0       0           1\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.33      0.40      0.36         5\n",
      "entertainment       0.67      0.80      0.73         5\n",
      "       sports       0.83      1.00      0.91         5\n",
      "   technology       0.50      0.20      0.29         5\n",
      "\n",
      "     accuracy                           0.60        20\n",
      "    macro avg       0.58      0.60      0.57        20\n",
      " weighted avg       0.58      0.60      0.57        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for test dataset\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.lm_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.lm_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc54b6",
   "metadata": {},
   "source": [
    "### Accuracy for the train dataset was pretty high at 93% but there is a pretty significant drop for the test dataset to 70%. Most of the misclassification looks to be from the business and technology categories which is not that surprising since they had many of the same top words due to the recent news about Meta/Facebook.\n",
    "\n",
    "# Exercise 1a\n",
    "\n",
    "What other types of models (i.e. different classifcation algorithms) could you use?\n",
    "\n",
    "### I will try a random forest model next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "995accbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest model object setting min samples per leaf and max depth\n",
    "rf = RandomForestClassifier(class_weight=None, \n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=369)\n",
    "# fit the random forest model\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "test['rf_predicted'] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "157922cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 86.25%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "rf_predicted                                              \n",
      "business             15              0       0           4\n",
      "entertainment         0             19       0           0\n",
      "sports                2              1      20           1\n",
      "technology            3              0       0          15\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.79      0.75      0.77        20\n",
      "entertainment       1.00      0.95      0.97        20\n",
      "       sports       0.83      1.00      0.91        20\n",
      "   technology       0.83      0.75      0.79        20\n",
      "\n",
      "     accuracy                           0.86        80\n",
      "    macro avg       0.86      0.86      0.86        80\n",
      " weighted avg       0.86      0.86      0.86        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for train dataset\n",
    "print('Accuracy of random forest classifier on training set: {:.2%}'\n",
    "      .format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aa9916b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 55.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "rf_predicted                                              \n",
      "business              1              0       0           3\n",
      "entertainment         1              5       1           1\n",
      "sports                2              0       4           0\n",
      "technology            1              0       0           1\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.25      0.20      0.22         5\n",
      "entertainment       0.62      1.00      0.77         5\n",
      "       sports       0.67      0.80      0.73         5\n",
      "   technology       0.50      0.20      0.29         5\n",
      "\n",
      "     accuracy                           0.55        20\n",
      "    macro avg       0.51      0.55      0.50        20\n",
      " weighted avg       0.51      0.55      0.50        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for test dataset\n",
    "print('Accuracy of random forest classifier on test set: {:.2%}'\n",
    "      .format(accuracy_score(test.actual, test.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.rf_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.rf_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec1045",
   "metadata": {},
   "source": [
    "### With an in-sample accuracy of 86% and an out-of-sample accuracy of 55% by the random forest model , the linear regression model produces the best results for this classification.\n",
    "\n",
    "# Exercise 1b\n",
    "\n",
    "How do the models compare when trained on term frequency data alone, instead of TF-IDF values?\n",
    "\n",
    "### Next I will try the random forest model with bag of words rather than TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eeca9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use count vectorizer object to create bag of words by fit and transform news_df data, assign category column to y variable\n",
    "cv = CountVectorizer()\n",
    "X_bag_of_words = cv.fit_transform(news_df.lemmatized)\n",
    "y = news_df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d06f8931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>107</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>120000</th>\n",
       "      <th>1206</th>\n",
       "      <th>...</th>\n",
       "      <th>yuvraj</th>\n",
       "      <th>yuzvendra</th>\n",
       "      <th>zalmi</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zapkeycom</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100  1000  107  10th  11  11th  12  120000  1206  ...  yuvraj  \\\n",
       "0    0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "1    0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "2    0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "3    0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "4    0    0     0    0     0   0     0   0       0     1  ...       0   \n",
       "..  ..  ...   ...  ...   ...  ..   ...  ..     ...   ...  ...     ...   \n",
       "95   0    0     0    0     1   0     0   0       0     0  ...       0   \n",
       "96   0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "97   0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "98   0    0     0    0     0   1     0   0       0     0  ...       0   \n",
       "99   0    0     0    0     0   0     0   0       0     0  ...       0   \n",
       "\n",
       "    yuzvendra  zalmi  zaman  zapkeycom  zero  zipping  zone  zucker  \\\n",
       "0           0      0      0          0     0        0     0       0   \n",
       "1           0      0      0          0     1        0     1       0   \n",
       "2           0      0      0          0     0        0     0       0   \n",
       "3           0      0      0          0     0        0     0       0   \n",
       "4           0      0      0          0     0        0     0       0   \n",
       "..        ...    ...    ...        ...   ...      ...   ...     ...   \n",
       "95          0      0      0          0     0        0     0       0   \n",
       "96          0      0      0          0     0        0     0       0   \n",
       "97          0      0      0          0     0        0     0       0   \n",
       "98          0      0      0          0     0        0     0       0   \n",
       "99          0      0      0          0     0        0     0       0   \n",
       "\n",
       "    zuckerberg  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            2  \n",
       "..         ...  \n",
       "95           0  \n",
       "96           0  \n",
       "97           0  \n",
       "98           0  \n",
       "99           0  \n",
       "\n",
       "[100 rows x 1810 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of words\n",
    "words = pd.DataFrame(X_bag_of_words.todense(), columns=cv.get_feature_names())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8da5c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into X train and test, and y train and test, stratifying on category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bag_of_words, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d1d39d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest model object setting min samples per leaf and max depth\n",
    "rf = RandomForestClassifier(class_weight=None, \n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=369)\n",
    "# fit the random forest model\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "test['rf_predicted'] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6cd38f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 85.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "rf_predicted                                              \n",
      "business             13              1       0           3\n",
      "entertainment         1             18       0           0\n",
      "sports                0              1      20           0\n",
      "technology            6              0       0          17\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.76      0.65      0.70        20\n",
      "entertainment       0.95      0.90      0.92        20\n",
      "       sports       0.95      1.00      0.98        20\n",
      "   technology       0.74      0.85      0.79        20\n",
      "\n",
      "     accuracy                           0.85        80\n",
      "    macro avg       0.85      0.85      0.85        80\n",
      " weighted avg       0.85      0.85      0.85        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for train dataset\n",
    "print('Accuracy of random forest classifier on training set: {:.2%}'\n",
    "      .format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "78db4023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 60.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         business  entertainment  sports  technology\n",
      "rf_predicted                                              \n",
      "business              3              1       1           2\n",
      "entertainment         0              4       1           0\n",
      "sports                0              0       3           1\n",
      "technology            2              0       0           2\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.43      0.60      0.50         5\n",
      "entertainment       0.80      0.80      0.80         5\n",
      "       sports       0.75      0.60      0.67         5\n",
      "   technology       0.50      0.40      0.44         5\n",
      "\n",
      "     accuracy                           0.60        20\n",
      "    macro avg       0.62      0.60      0.60        20\n",
      " weighted avg       0.62      0.60      0.60        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate results for test dataset\n",
    "print('Accuracy of random forest classifier on test set: {:.2%}'\n",
    "      .format(accuracy_score(test.actual, test.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.rf_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.rf_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e8818",
   "metadata": {},
   "source": [
    "### The random forest model does perform better on bag of words than TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b8153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
